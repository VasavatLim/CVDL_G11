# 5: Generative Models Lab

## Introduction
In this lab, you will build a generative model that produces cat images using diffusion-based techniques. Your focus will be on developing a noise scheduler, handling timestep encodings, and implementing the model components. You will also refine the training process to evaluate and compare different scheduler configurations.

## Task I: Understand the Architecture (1P)
Your first task is to familiarize yourself with the diffusion model architecture and review the corresponding code.

1. **Study the Literature**
   - Read the Denoising Diffusion Probabilistic Models publication to gain a general understanding of the architecture.
   - Refer to additional resources such as "The Annotated Diffusion Model" and "What are Diffusion Models?" for further insights.

2. **Analyze the Model Code**
   - Examine the components in `model.py` to understand how the model is constructed.
   - Explain the purpose and significance of the different arguments provided to the `SDUNet` function.

3. **Implement a ResBlock**
   - Complete the `TODO` by adding a ResBlock component in the model.


## Task II: Implement Noise Scheduler (1P)
In this task, you will extend the noise scheduling component by adding a new scheduler class.

1. **Extend the Abstract Class**
   - In `noise_scheduler.py`, start with the existing abstract NoiseScheduler class and the provided LinearNoiseScheduler.
   - Create an additional scheduler class (for example, using a cosine, sigmoid, or cubic schedule).
   - **Hint:** Implement only the `calc_betas` method in your new class.

2. **Visualize Scheduler Outputs**
   - Plot the beta and alpha values generated by the different schedulers.
   - Explain the role of the alphas in the reverse diffusion process.


## Task III: Determine Noise Scheduler Parameters (2P)
Here you will explore how the parameters of your noise scheduler affect the diffusion process.

1. **Visualize the Forward Diffusion Process**
   - Create a script to visualize the progression of noisy images at different timesteps during the forward diffusion process.
   - **Hint:** The `add_noise` method requires the noise to have the same shape as the original image (`x0`), and you can use `torch.randn_like` to sample noise.

2. **Analyze RGB Channel Distributions**
   - Enhance your script to display the distribution of pixel values for each RGB color channel.

3. **Determine Degradation Parameters**
   - For each scheduler, determine the combination of timesteps and beta values required to fully degrade an input image into noise.
   - Compare your findings and discuss how the number of timesteps influences the degradation process.

4. **Discuss Trade-offs**
   - Explain the potential benefits and drawbacks of schedulers that degrade an image quickly versus those that do so gradually.
   - **Hint:** Consider how the speed of degradation might affect the fidelity of the generated image during the reverse process.


## Task IV: Training & Validation (4P)
Your next step is to train your model and evaluate its performance.

1. **Initial Training Run**
   - Use the `train.py` script with the provided configuration to train your model.
   - Evaluate whether the loss function is a reliable indicator of model performance and assess the visual quality of the generated images.

2. **TensorBoard Integration**
   - Modify `train.py` so that an image is generated at the end of each epoch and logged with TensorBoard.
   - **Hint:** Refer to the PyTorch TensorBoard documentation for guidance. Use the functions defined in `sample.py` to generate images.

3. **Explore Model Variants**
   - Train multiple model variations using different noise schedulers and document your findings.
   - Provide an analysis on the following points:
     - Which noise scheduler produced the best results?
     - How do changes in the attention layer or replacing a ConvBlock with a ResBlock impact performance?
     - Does a deeper network yield better image quality?


## Task V: (Optional) Making an Image Artifact Remover (2P)
For added challenge, develop a method to denoise images that contain artifacts.

1. **Identify a Suitable Timestep**
   - Using your noise scheduler, determine a timestep $$T$$ at which an image is still recognizable but significantly degraded.

2. **Develop the Artifact Removal Script**
   - Create a script that uses your model to denoise a seed image by first adding noise at timestep $$T$$ and then generating a cleaned version.
    - *Hint:** You can find a sample image with jpeg artifacts here: [img-clean](https://drive.switch.ch/index.php/s/xvI7eOqrQREeOno), [img-artifacts](https://drive.switch.ch/index.php/s/nJqp1UDVkLxELvq).

3. **Analyze the Results**
   - Describe the quality of the denoised image, noting any issues such as the generation of incorrect details or artifacts.


## Task VI: (Optional) Further Exploration (2P)
For further investigation and to deepen your understanding, consider one of the following exploratory tasks:

1. **Image Upscaling**
   - Experiment with image upscaling techniques, such as the Stable Diffusion x4 upscaler, to improve the resolution of your generated images.

2. **Build a Web App**
   - Develop a web application using Streamlit that allows users to generate images from a given seed.

3. **Alternate Datasets**
   - Investigate the use of another dataset, such as the Flowers102 dataset, to test the versatility of your model.


---

### Notes:
- **Evaluation Criteria**: Each task is assigned points (P) based on its complexity. Ensure your submission includes detailed explanations to get all the points.
- **Deliverables**: Show your scripts, explanations, and any visualizations generated during the lab hand-in session.
- **Hints**: Read the provided hints carefully; they are meant to guide you through the more challenging aspects of the tasks.
